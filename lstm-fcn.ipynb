{"cells":[{"cell_type":"markdown","metadata":{},"source":["# LSTM-FCN for anomaly detection in GPVS"]},{"cell_type":"markdown","metadata":{},"source":["## Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:31:37.323765Z","iopub.status.busy":"2023-09-21T10:31:37.323344Z","iopub.status.idle":"2023-09-21T10:31:43.361641Z","shell.execute_reply":"2023-09-21T10:31:43.360573Z","shell.execute_reply.started":"2023-09-21T10:31:37.323736Z"},"id":"NKPoS5uz8Huo","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from tqdm.auto import tqdm\n","\n","import torch\n","import torch.autograd as autograd\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","import scipy.io as sio\n","import time\n","import os\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sn"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:31:43.369443Z","iopub.status.busy":"2023-09-21T10:31:43.366943Z","iopub.status.idle":"2023-09-21T10:31:43.424978Z","shell.execute_reply":"2023-09-21T10:31:43.423964Z","shell.execute_reply.started":"2023-09-21T10:31:43.369407Z"},"id":"Rj5CPPF8A8TU","outputId":"ee345a7d-779c-4b0b-b060-18660a03ec11","trusted":true},"outputs":[],"source":["print(torch.__version__)\n","print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0))\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:31:43.431747Z","iopub.status.busy":"2023-09-21T10:31:43.429310Z","iopub.status.idle":"2023-09-21T10:31:43.440595Z","shell.execute_reply":"2023-09-21T10:31:43.439527Z","shell.execute_reply.started":"2023-09-21T10:31:43.431687Z"},"id":"OP-bzylgD8aU","trusted":true},"outputs":[],"source":["learning_rate = 1e-4\n","num_epoch = 30\n","batch_size = 128\n","gan = False\n","sampler = False"]},{"cell_type":"markdown","metadata":{"id":"GNlfPeRTHfpI"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:31:43.448785Z","iopub.status.busy":"2023-09-21T10:31:43.447349Z","iopub.status.idle":"2023-09-21T10:31:43.460909Z","shell.execute_reply":"2023-09-21T10:31:43.459638Z","shell.execute_reply.started":"2023-09-21T10:31:43.448751Z"},"id":"8hftRKTb8Qu4","trusted":true},"outputs":[],"source":["class GPVSDataset(Dataset):\n","    def __init__(self, df, feature_columns):\n","        super().__init__()\n","        self.df = df\n","        self.sequences = self.df[feature_columns]\n","        self.labels = self.df['Fault_type']\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        sequence = np.array([np.array(item) for item in self.sequences.iloc[idx, :]]).T\n","        label = self.labels[idx]\n","        return dict(\n","            sequence = torch.Tensor(sequence),\n","            label = torch.tensor(label).long()\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:31:43.468220Z","iopub.status.busy":"2023-09-21T10:31:43.465844Z","iopub.status.idle":"2023-09-21T10:32:21.844501Z","shell.execute_reply":"2023-09-21T10:32:21.843488Z","shell.execute_reply.started":"2023-09-21T10:31:43.468184Z"},"id":"oKOBk4nEITom","trusted":true},"outputs":[],"source":["dataset_folder = '/kaggle/input/gpvs-gan-dataset/gpvs_sl200_s15'\n","filenames = os.listdir(dataset_folder)\n","\n","if gan:\n","    train_df = pd.read_pickle(os.path.join(dataset_folder,[filename for filename in filenames if 'GAN' in filename][0]))\n","else:\n","    train_df = pd.read_pickle(os.path.join(dataset_folder,[filename for filename in filenames if 'TRAIN' in filename][0]))\n","\n","val_df = pd.read_pickle(os.path.join(dataset_folder,[filename for filename in filenames if 'VALI' in filename][0]))\n","test_df = pd.read_pickle(os.path.join(dataset_folder,[filename for filename in filenames if 'TEST' in filename][0]))\n","\n","le = LabelEncoder()\n","le.fit(train_df['Fault_type'])\n","\n","train_df['Fault_type'] = le.transform(train_df['Fault_type'])\n","val_df['Fault_type'] = le.transform(val_df['Fault_type'])\n","test_df['Fault_type'] = le.transform(test_df['Fault_type'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:32:21.846448Z","iopub.status.busy":"2023-09-21T10:32:21.846108Z","iopub.status.idle":"2023-09-21T10:32:21.854278Z","shell.execute_reply":"2023-09-21T10:32:21.853361Z","shell.execute_reply.started":"2023-09-21T10:32:21.846417Z"},"id":"DjdSeDgqKt3W","trusted":true},"outputs":[],"source":["print(f'Train set lenght: {len(train_df)}')\n","print(f'Validation set lenght: {len(val_df)}')\n","print(f'Test set lenght: {len(test_df)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:32:21.856614Z","iopub.status.busy":"2023-09-21T10:32:21.855768Z","iopub.status.idle":"2023-09-21T10:32:21.865023Z","shell.execute_reply":"2023-09-21T10:32:21.863936Z","shell.execute_reply.started":"2023-09-21T10:32:21.856578Z"},"trusted":true},"outputs":[],"source":["le.classes_"]},{"cell_type":"markdown","metadata":{},"source":["## DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:32:21.867074Z","iopub.status.busy":"2023-09-21T10:32:21.866607Z","iopub.status.idle":"2023-09-21T10:32:21.877327Z","shell.execute_reply":"2023-09-21T10:32:21.876348Z","shell.execute_reply.started":"2023-09-21T10:32:21.867041Z"},"trusted":true},"outputs":[],"source":["def getSampler(df, label_column):\n","    class_occ = pd.DataFrame()\n","    class_occ['Occ'] = df[label_column].value_counts().sort_index()\n","    class_occ['weight'] = class_occ['Occ'].apply(lambda x: 1./x)\n","    #print(class_occ)\n","    \n","    weights_dict = class_occ['weight'].to_dict()\n","    df['weight'] = df[label_column].apply(lambda x: weights_dict[x])\n","    #print(df)\n","    \n","    weights = torch.DoubleTensor(df.weight.values)\n","    #print('weights: ', weights)\n","\n","    sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights), replacement=True)\n","    return sampler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:32:21.879416Z","iopub.status.busy":"2023-09-21T10:32:21.879039Z","iopub.status.idle":"2023-09-21T10:32:21.909127Z","shell.execute_reply":"2023-09-21T10:32:21.908271Z","shell.execute_reply.started":"2023-09-21T10:32:21.879384Z"},"id":"bSByfhsSNj7P","trusted":true},"outputs":[],"source":["feature_columns = ['Ipv', 'Vpv', 'Vdc', 'ia', 'ib', 'ic', 'va', 'vb', 'vc', 'Iabc', 'If', 'Vabc', 'Vf']\n","\n","train_data = GPVSDataset(train_df, feature_columns)\n","if sampler and not gan:\n","    train_sampler = getSampler(train_df, 'Fault_type')\n","    train_dataloader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, shuffle=False)\n","else:\n","    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","\n","val_data = GPVSDataset(val_df, feature_columns)\n","val_dataloader = DataLoader(val_data, batch_size=batch_size)\n","\n","dataloaders = {\n","   'train': train_dataloader,\n","    'validation': val_dataloader\n","}\n","\n","dataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'validation']}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:32:21.913218Z","iopub.status.busy":"2023-09-21T10:32:21.912958Z","iopub.status.idle":"2023-09-21T10:32:21.919020Z","shell.execute_reply":"2023-09-21T10:32:21.917929Z","shell.execute_reply.started":"2023-09-21T10:32:21.913194Z"},"trusted":true},"outputs":[],"source":["def countLabels(dataloader, class_names):\n","    labels_count = {x: 0 for x in class_names}\n","\n","    for data in dataloader:\n","        labels = data['label']\n","        for idx in range(len(class_names)):\n","            labels_count[class_names[idx]] += torch.sum(labels == idx).item()\n","        \n","    return labels_count"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:32:21.921369Z","iopub.status.busy":"2023-09-21T10:32:21.920985Z","iopub.status.idle":"2023-09-21T10:32:21.928027Z","shell.execute_reply":"2023-09-21T10:32:21.926894Z","shell.execute_reply.started":"2023-09-21T10:32:21.921281Z"},"trusted":true},"outputs":[],"source":["#labels_count = countLabels(train_dataloader, le.classes_)\n","#labels_count"]},{"cell_type":"markdown","metadata":{"id":"gQbd6zPHHbo-"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:32:21.929930Z","iopub.status.busy":"2023-09-21T10:32:21.929580Z","iopub.status.idle":"2023-09-21T10:32:21.938778Z","shell.execute_reply":"2023-09-21T10:32:21.937190Z","shell.execute_reply.started":"2023-09-21T10:32:21.929899Z"},"id":"GraYvu4H95WE","trusted":true},"outputs":[],"source":["class LSTM_FCN(nn.Module):\n","    def __init__(self, n_features, n_classes, n_hidden=256, n_layers=3):\n","        super().__init__()\n","\n","        self.lstm = nn.LSTM(\n","            input_size = n_features,\n","            hidden_size = n_hidden,\n","            batch_first = True,\n","            num_layers = n_layers, # Stack LSTMs\n","            dropout = 0.2  # This model works on a lot of regularisation\n","        )\n","\n","        self.classifier = nn.Linear(n_hidden, n_classes)\n","\n","    def forward(self, x):\n","        self.lstm.flatten_parameters()  # For distrubuted training\n","\n","        _, (hidden, _) = self.lstm(x)\n","        # We want the output from the last layer to go into the final\n","        # regressor linear layer\n","        out = hidden[-1]\n","\n","        return self.classifier(out)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:32:21.941488Z","iopub.status.busy":"2023-09-21T10:32:21.940384Z","iopub.status.idle":"2023-09-21T10:32:27.165797Z","shell.execute_reply":"2023-09-21T10:32:27.164769Z","shell.execute_reply.started":"2023-09-21T10:32:21.941455Z"},"id":"g8KatzE7G522","trusted":true},"outputs":[],"source":["model = LSTM_FCN(n_features=len(feature_columns), n_classes=len(le.classes_)).to(device)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer_ft = optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, patience = 3, verbose = True)"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:32:27.167511Z","iopub.status.busy":"2023-09-21T10:32:27.167167Z","iopub.status.idle":"2023-09-21T10:32:27.204046Z","shell.execute_reply":"2023-09-21T10:32:27.202855Z","shell.execute_reply.started":"2023-09-21T10:32:27.167475Z"},"id":"-g_dA5jbHFJd","trusted":true},"outputs":[],"source":["#find best model on validation test\n","def train_loop_validation(dataloaders, startEpoch, numEpochs, model_conv, criterionCNN, optimizer_conv, scheduler,\n","                          best_acc, best_loss, best_epoca, outputPath):\n","  \n","  for epochs in range(startEpoch, numEpochs + 1):\n","    since = time.time()\n","    \n","    modelLoss_train = 0.0\n","    modelAcc_train = 0.0\n","\n","    model_conv.train() \n","\n","    totalSize = 0\n","    \n","    #for each batch\n","    for data in dataloaders['train']:\n","        inputs = data['sequence'].type(torch.FloatTensor).to(device)\n","        labels = data['label'].to(device)\n","      \n","        optimizer_conv.zero_grad()\n","        model_conv.zero_grad()\n","      \n","        y = model_conv(inputs)\n","        outp, preds = torch.max(y, 1)   \n","        \n","        lossCNN = criterionCNN(y, labels) #media per batch \n","\n","        modelLoss_train += lossCNN.item() * inputs.size(0)\n","        totalSize += inputs.size(0)\n","        modelAcc_train += torch.sum(preds == labels.data).item()\n","\n","        lossCNN.backward()  # pred = f(x)   -> loss = L(f(x), l_true)\n","    \n","        optimizer_conv.step()\n","    \n","    \n","    modelLoss_epoch_train = modelLoss_train/totalSize\n","    modelAcc_epoch_train  = modelAcc_train/totalSize\n","    \n","    #salvataggio dei pesi ad ogni iterazione -> nel caso si blocchi e vogliamo riprendere il train \n","    torch.save(model_conv.state_dict(), outputPath + 'train_weights.pth')\n","    \n","    model_conv.eval()\n","    totalSize_val = 0\n","    modelLoss_val = 0.0\n","    modelAcc_val = 0.0\n","\n","    for data in dataloaders['validation']:\n","        inputs = data['sequence'].type(torch.FloatTensor).cuda()\n","        labels = data['label'].cuda()\n","      \n","        y = model_conv(inputs)\n","        outp, preds = torch.max(y, 1) \n","        lossCNN = criterionCNN(y, labels)\n","\n","        modelLoss_val += lossCNN.item() * inputs.size(0)\n","        totalSize_val += inputs.size(0)\n","        modelAcc_val += torch.sum(preds == labels.data).item()\n","    \n","    modelLoss_epoch_val=modelLoss_val/totalSize_val\n","    modelAcc_epoch_val = modelAcc_val/totalSize_val\n","    time_elapsed = time.time()-since\n","    \n","    scheduler.step(modelLoss_epoch_val)\n","\n","    #print(time_elapsed)\n","    print('[Epoch %d][TRAIN on %d [Loss: %.4f  ACC: %.4f]][VAL on %d [Loss: %.4f  ACC: %.4f]][TIME: %.0f m %.0f s]' \n","          %(epochs, totalSize, modelLoss_epoch_train, modelAcc_epoch_train, totalSize_val, modelLoss_epoch_val, \n","            modelAcc_epoch_val, time_elapsed // 60, time_elapsed % 60))\n","    \n","    #if epochs == 1 or modelLoss_epoch_val < best_loss:\n","    if (modelAcc_epoch_val > best_acc) or (modelAcc_epoch_val == best_acc and modelLoss_epoch_val < best_loss) :\n","        print('     .... Saving best weights ....')\n","        best_acc = modelAcc_epoch_val\n","        best_loss = modelLoss_epoch_val\n","        best_epoca = epochs\n","        #salvataggio dei migliori pesi sul validation\n","        torch.save(model_conv.state_dict(), outputPath + 'best_model_weights.pth')\n","      \n","    \n","    with open(outputPath + 'learningRate.txt', \"a\") as file_object:\n","        file_object.write(str(optimizer_ft.param_groups[0]['lr']) +'\\n')\n","    \n","    with open(outputPath + 'lossTrain.txt', \"a\") as file_object:\n","        file_object.write(str(modelLoss_epoch_train) +'\\n')\n","      \n","    with open(outputPath + 'AccTrain.txt', \"a\") as file_object:\n","        file_object.write(str(modelAcc_epoch_train)+'\\n')\n","      \n","    with open(outputPath + 'lossVal.txt', \"a\") as file_object:\n","        file_object.write(str(modelLoss_epoch_val)+'\\n')\n","      \n","    with open(outputPath + 'AccVal.txt', \"a\") as file_object:\n","        file_object.write(str(modelAcc_epoch_val)+'\\n')\n","      \n","    sio.savemat(outputPath + 'check_point.mat', {'best_acc': best_acc, \n","                                                 'best_loss': best_loss,\n","                                                 'best_epoca': best_epoca,\n","                                                 'last_epoch': epochs})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:32:27.206127Z","iopub.status.busy":"2023-09-21T10:32:27.205779Z","iopub.status.idle":"2023-09-21T10:37:43.477851Z","shell.execute_reply":"2023-09-21T10:37:43.476778Z","shell.execute_reply.started":"2023-09-21T10:32:27.206094Z"},"id":"iL5jfGlcHJnx","trusted":true},"outputs":[],"source":["startEpoch = 1\n","best_acc = 0\n","best_loss= 0\n","best_epoca = 0\n","WeightPath = './'\n","train_loop_validation(dataloaders, startEpoch, num_epoch, model, criterion, optimizer_ft, scheduler, best_acc, best_loss, best_epoca, WeightPath)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:37:43.479692Z","iopub.status.busy":"2023-09-21T10:37:43.479260Z","iopub.status.idle":"2023-09-21T10:37:44.691611Z","shell.execute_reply":"2023-09-21T10:37:44.690649Z","shell.execute_reply.started":"2023-09-21T10:37:43.479657Z"},"id":"4wotfJm1HPFN","trusted":true},"outputs":[],"source":["lossModel_Train = []\n","lossModel_val = []\n","accModel_Train = []\n","accModel_val = []\n","lrs = []\n","\n","WeightPath = './'\n","file = open(WeightPath + 'lossTrain.txt', 'r')\n","Testo = file.readlines()\n","for element in Testo:\n","    lossModel_Train.append(float(element))\n","\n","file = open(WeightPath + 'lossVal.txt', 'r')\n","Testo = file.readlines()\n","for element in Testo:\n","    lossModel_val.append(float(element))\n","\n","plt.figure()\n","plt.title(\"Model: Training Vs Validation Losses\")\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.plot(list(range(1,len(lossModel_Train)+1)), lossModel_Train, color='r', label=\"Training Loss\")\n","plt.plot(list(range(1, len(lossModel_val)+1)), lossModel_val, color='g', label=\"Validation Loss\")\n","plt.legend()\n","plt.savefig(WeightPath + 'LossTrainVal.png')\n","\n","file = open(WeightPath + 'AccTrain.txt', 'r')\n","Testo = file.readlines()\n","for element in Testo:\n","    accModel_Train.append(float(element))\n","\n","file = open(WeightPath + 'AccVal.txt', 'r')\n","Testo = file.readlines()\n","for element in Testo:\n","    accModel_val.append(float(element))\n","\n","plt.figure()\n","plt.title(\"Training Vs Validation Accuracies\")\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.plot(list(range(1, len(accModel_Train)+1)), accModel_Train, color='r', label=\"Training Accuracy\")\n","plt.plot(list(range(1, len(accModel_val)+1)), accModel_val, color='g', label=\"Validation Accuracy\")\n","plt.legend()\n","plt.savefig(WeightPath + 'AccTrainVal.png')\n","\n","file = open(WeightPath + 'learningRate.txt', 'r')\n","Testo = file.readlines()\n","for element in Testo:\n","    lrs.append(float(element))\n","\n","plt.figure()\n","plt.title(\"Learning Rate\")\n","plt.xlabel('Epoch')\n","plt.ylabel('lr')\n","plt.plot(list(range(1, len(lrs)+1)), lrs, color='b')\n","plt.savefig(WeightPath + 'AccTrainVal.png')"]},{"cell_type":"markdown","metadata":{"id":"xDjeGnphPUcr"},"source":["### Load best weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:37:44.693497Z","iopub.status.busy":"2023-09-21T10:37:44.693142Z","iopub.status.idle":"2023-09-21T10:37:44.707559Z","shell.execute_reply":"2023-09-21T10:37:44.706674Z","shell.execute_reply.started":"2023-09-21T10:37:44.693463Z"},"id":"jHpNQPSlHQL-","trusted":true},"outputs":[],"source":["weight_path = './best_model_weights.pth'\n","checkpoint = torch.load(weight_path)\n","model.load_state_dict(checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"O6WNfBrtPSdP"},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:37:44.709367Z","iopub.status.busy":"2023-09-21T10:37:44.709018Z","iopub.status.idle":"2023-09-21T10:39:46.033442Z","shell.execute_reply":"2023-09-21T10:39:46.032407Z","shell.execute_reply.started":"2023-09-21T10:37:44.709334Z"},"id":"Tvqo_ljRHUMz","trusted":true},"outputs":[],"source":["test_data = GPVSDataset(test_df.reset_index(drop=True), feature_columns)\n","test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)\n","\n","correct = 0\n","total = 0\n","model.eval()\n","Test_results = pd.DataFrame()\n","\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","    for data in test_dataloader:\n","        inputs, labels = data['sequence'], data['label']\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # calculate outputs by running images through the network\n","        outputs = model(inputs)\n","        # the class with the highest energy is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        #print(predicted, labels, predicted == labels)\n","        correct += (predicted == labels).sum().item()\n","\n","        Test_results = pd.concat([Test_results, pd.DataFrame({'label': [int(labels.item())], 'pred': [int(predicted.item())]})], ignore_index = True)\n","\n","print(f'Accuracy of the network on the test sequences: {100 * correct // total} %')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:39:46.035946Z","iopub.status.busy":"2023-09-21T10:39:46.034860Z","iopub.status.idle":"2023-09-21T10:39:47.212554Z","shell.execute_reply":"2023-09-21T10:39:47.211633Z","shell.execute_reply.started":"2023-09-21T10:39:46.035907Z"},"id":"i0E6G-2FQW2h","trusted":true},"outputs":[],"source":["c = confusion_matrix(Test_results['label'],Test_results['pred'])\n","df_cm = pd.DataFrame(c , index = le.classes_, columns = le.classes_)\n","plt.figure(figsize = (20,20))\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","sn.heatmap(df_cm, annot=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T10:39:47.214828Z","iopub.status.busy":"2023-09-21T10:39:47.213640Z","iopub.status.idle":"2023-09-21T10:39:47.255835Z","shell.execute_reply":"2023-09-21T10:39:47.254767Z","shell.execute_reply.started":"2023-09-21T10:39:47.214789Z"},"id":"NmfX0G2WS2pp","trusted":true},"outputs":[],"source":["print(classification_report(Test_results['label'],Test_results['pred'], target_names = le.classes_))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
